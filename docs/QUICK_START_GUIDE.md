# ğŸš€ QUICK START GUIDE - REAL-TIME MOVIE RECOMMENDATION SYSTEM

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## ğŸ“ PROJECT STRUCTURE

```
project-root/
â”‚
â”œâ”€ docker-compose.unified.yaml    # Main orchestration file
â”‚
â”œâ”€ init-scripts/
â”‚  â””â”€ init-pgvector.sql           # Database initialization
â”‚
â”œâ”€ spark/
â”‚  â””â”€ Dockerfile                  # Spark container image
â”‚
â”œâ”€ spark-jobs/
â”‚  â””â”€ streaming_recommendations.py # Real-time processing job
â”‚
â”œâ”€ airflow/
â”‚  â”œâ”€ Dockerfile                  # Airflow container image
â”‚  â”œâ”€ logs/                       # Task execution logs (auto-created)
â”‚  â””â”€ plugins/                    # Custom operators (optional)
â”‚
â”œâ”€ dags/
â”‚  â””â”€ (your batch ETL DAGs)       # Airflow workflows
â”‚
â”œâ”€ fastapi/
â”‚  â”œâ”€ Dockerfile                  # FastAPI container image
â”‚  â”œâ”€ requirements.txt            # Python dependencies
â”‚  â””â”€ app/
â”‚     â””â”€ main.py                  # API application
â”‚
â””â”€ REAL_TIME_LAYER_GUIDE.md       # Architecture documentation

```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## âš¡ 5-MINUTE SETUP

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

### Step 1: Prerequisites

Äáº£m báº£o anh Ä‘Ã£ cÃ³:
```bash
âœ… Docker Desktop (with 8GB RAM allocated)
âœ… Docker Compose V2
âœ… At least 20GB free disk space
âœ… Mac M4 (hoáº·c tÆ°Æ¡ng tá»±)

# Verify installations
docker --version          # Should be 20.x or higher
docker compose version    # Should be 2.x
```

---

### Step 2: Project Setup

```bash
# Create project directory
mkdir -p ~/movie-recommendation-system
cd ~/movie-recommendation-system

# Create all required subdirectories
mkdir -p spark spark-jobs airflow/logs airflow/plugins dags fastapi/app init-scripts

# Copy all files from Claude's output into corresponding directories
# (Files are ready in /home/claude/)
```

---

### Step 3: Launch the System

```bash
# Start all services
docker compose -f docker-compose.unified.yaml up -d

# Wait for services to be healthy (~2-3 minutes)
# You can monitor progress with:
docker compose ps
```

Expected output when all services are ready:
```
NAME              STATUS                    PORTS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
minio             Up (healthy)              9000-9001
postgres          Up (healthy)              5432
redis             Up (healthy)              6379
zookeeper         Up (healthy)              2181
kafka             Up (healthy)              9092
kafka-ui          Up                        8081
spark-master      Up (healthy)              7077, 8088
spark-worker      Up                        8089
airflow-webserver Up (healthy)              8080
airflow-scheduler Up                        -
fastapi           Up (healthy)              8000
```

---

### Step 4: Verify Installation

Open these URLs in browser:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Service              â”‚ URL                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ FastAPI Docs         â”‚ http://localhost:8000/docs          â”‚
â”‚ FastAPI Health       â”‚ http://localhost:8000/health        â”‚
â”‚ Airflow UI           â”‚ http://localhost:8080               â”‚
â”‚                      â”‚ (admin/admin)                       â”‚
â”‚ Spark Master UI      â”‚ http://localhost:8088               â”‚
â”‚ Kafka UI             â”‚ http://localhost:8081               â”‚
â”‚ MinIO Console        â”‚ http://localhost:9001               â”‚
â”‚                      â”‚ (minioadmin/minioadmin)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

All pages should load successfully! âœ…

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## ğŸ§ª TESTING THE PIPELINE

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

### Test 1: Send a User Event

```bash
# Simulate user clicking on "Inception"
curl -X POST http://localhost:8000/api/events \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "test_user_1",
    "movie_id": "m002",
    "event_type": "click"
  }'

# Expected response:
{
  "status": "accepted",
  "message": "Event queued for processing",
  "timestamp": "2024-01-15T20:30:45.123456"
}
```

### Test 2: Start Spark Streaming Job

```bash
# Submit streaming job to Spark cluster
docker exec -it spark-master \
  /opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --deploy-mode client \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 \
  /opt/spark-jobs/streaming_recommendations.py

# You should see logs:
ğŸš€ Starting Real-Time Recommendation Engine
ğŸ“¡ Kafka: kafka:29092, Topic: movie-events
âœ… Streaming job started successfully. Processing events...
```

**IMPORTANT**: Keep this terminal open! Streaming job runs continuously.

### Test 3: Verify Event Processing

```bash
# Open Kafka UI: http://localhost:8081
# Navigate to: Topics â†’ movie-events â†’ Messages

# You should see your event:
{
  "event_id": "abc-123-...",
  "user_id": "test_user_1",
  "movie_id": "m002",
  "event_type": "click",
  "timestamp": "2024-01-15T20:30:45Z"
}
```

### Test 4: Check Recommendations

```bash
# Wait 5-10 seconds for processing, then:
curl "http://localhost:8000/api/recommendations?user_id=test_user_1&limit=5"

# Expected response:
{
  "user_id": "test_user_1",
  "recommendations": [
    {
      "movie_id": "m003",
      "title": "Interstellar",
      "genres": ["Sci-Fi", "Drama"],
      "score": 0.94
    },
    ...
  ],
  "source": "redis_cache",  # or "postgres_realtime"
  "generated_at": "2024-01-15T20:30:50.123456"
}
```

### Test 5: Load Testing (Optional)

```bash
# Install test tool
pip install httpie

# Send 100 events rapidly
for i in {1..100}; do
  http POST localhost:8000/api/events \
    user_id="user_$i" \
    movie_id="m$((RANDOM % 5 + 1))" \
    event_type=click &
done

# Check metrics
http localhost:8000/metrics

# Expected output:
{
  "total_requests": 100,
  "cache_hit_rate": 0.75,
  "avg_response_time_ms": 15.3
}
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## ğŸ› ï¸ COMMON OPERATIONS

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

### View Logs

```bash
# All services
docker compose -f docker-compose.unified.yaml logs -f

# Specific service
docker compose -f docker-compose.unified.yaml logs -f fastapi
docker compose -f docker-compose.unified.yaml logs -f kafka
docker compose -f docker-compose.unified.yaml logs -f spark-worker

# Spark Streaming job (if running in container)
docker logs -f spark-worker | grep "Processing micro-batch"
```

### Restart Services

```bash
# Restart single service
docker compose -f docker-compose.unified.yaml restart fastapi

# Restart all services
docker compose -f docker-compose.unified.yaml restart

# Full rebuild (after code changes)
docker compose -f docker-compose.unified.yaml up -d --build
```

### Access Database

```bash
# Connect to Postgres
docker exec -it postgres psql -U airflow -d moviedb

# Useful queries:
\dt                                    # List tables
SELECT COUNT(*) FROM movies;           # Check movie count
SELECT COUNT(*) FROM rt_user_interactions;  # Check events
SELECT * FROM user_profiles LIMIT 5;   # View user vectors

# Check pgvector
SELECT movie_id, title FROM movies WHERE embedding IS NOT NULL LIMIT 3;
```

### Access Redis

```bash
# Connect to Redis
docker exec -it redis redis-cli

# Useful commands:
KEYS recs:*                    # List all cached recommendations
GET recs:test_user_1           # View specific user's cache
TTL recs:test_user_1           # Check expiration time
DBSIZE                         # Total keys in cache
INFO memory                    # Memory usage
```

### Check Kafka Topics

```bash
# List topics
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 --list

# Describe topic
docker exec -it kafka kafka-topics \
  --bootstrap-server localhost:9092 \
  --describe \
  --topic movie-events

# Consume messages (real-time monitoring)
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic movie-events \
  --from-beginning
```

### Stop System

```bash
# Stop all services (preserves data)
docker compose -f docker-compose.unified.yaml stop

# Stop and remove containers (preserves volumes)
docker compose -f docker-compose.unified.yaml down

# Complete cleanup (âš ï¸ DELETES ALL DATA)
docker compose -f docker-compose.unified.yaml down -v
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## ğŸ› TROUBLESHOOTING

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

### Problem: Services won't start

```bash
# Check Docker resources
docker system df                 # Disk usage
docker stats                     # Memory/CPU usage

# Common fixes:
docker system prune -f           # Clean unused containers
docker volume prune -f           # Clean unused volumes
```

### Problem: Kafka connection errors

```bash
# Verify Kafka is ready
docker logs kafka | grep "started"

# Should see:
[KafkaServer id=1] started (kafka.server.KafkaServer)

# If not, wait 30 more seconds or restart:
docker compose restart kafka
```

### Problem: Spark Streaming job crashes

```bash
# Check worker logs
docker logs spark-worker

# Common issues:
1. OutOfMemoryError â†’ Reduce batch size in streaming job
2. Connection timeout â†’ Kafka/Postgres not ready, wait and retry
3. Import errors â†’ Missing dependencies, rebuild container
```

### Problem: FastAPI returns 500 errors

```bash
# Check API logs
docker logs fastapi

# Test database connection
docker exec -it fastapi python -c "
import asyncpg
import asyncio
async def test():
    conn = await asyncpg.connect('postgresql://airflow:airflow@postgres:5432/moviedb')
    print(await conn.fetchval('SELECT 1'))
asyncio.run(test())
"

# Should print: 1
```

### Problem: No recommendations returned

```bash
# Check if sample data loaded
docker exec -it postgres psql -U airflow -d moviedb -c \
  "SELECT COUNT(*) FROM movies;"

# Should be > 0

# If 0, re-run initialization:
docker exec -it postgres psql -U airflow -d moviedb \
  -f /docker-entrypoint-initdb.d/01-init-pgvector.sql
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## ğŸ“Š MONITORING DASHBOARD

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

### Health Check Dashboard

Create a simple monitoring script:

```bash
#!/bin/bash
# health_check.sh

echo "ğŸ¥ System Health Check"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

# FastAPI
echo -n "FastAPI:    "
curl -s http://localhost:8000/health | jq -r '.status' || echo "âŒ DOWN"

# Airflow
echo -n "Airflow:    "
curl -s http://localhost:8080/health | jq -r '.status' || echo "âŒ DOWN"

# Spark
echo -n "Spark:      "
curl -s http://localhost:8088 > /dev/null && echo "âœ… UP" || echo "âŒ DOWN"

# Kafka
echo -n "Kafka UI:   "
curl -s http://localhost:8081 > /dev/null && echo "âœ… UP" || echo "âŒ DOWN"

# Postgres
echo -n "Postgres:   "
docker exec postgres pg_isready -U airflow > /dev/null && echo "âœ… UP" || echo "âŒ DOWN"

# Redis
echo -n "Redis:      "
docker exec redis redis-cli ping | grep -q PONG && echo "âœ… UP" || echo "âŒ DOWN"

echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

# Performance Metrics
echo ""
echo "ğŸ“ˆ Performance Metrics"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
curl -s http://localhost:8000/metrics | jq '.'
```

Run it:
```bash
chmod +x health_check.sh
./health_check.sh
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## ğŸ¯ NEXT STEPS

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

### Phase 1: Enhancements (Week 1-2)
```
â”œâ”€ Add more sophisticated recommendation algorithms
â”œâ”€ Implement A/B testing framework
â”œâ”€ Add real movie dataset (MovieLens, TMDB)
â””â”€ Create simple web UI for testing
```

### Phase 2: Production Hardening (Week 3-4)
```
â”œâ”€ Add authentication (JWT)
â”œâ”€ Implement monitoring (Prometheus + Grafana)
â”œâ”€ Set up CI/CD pipeline
â””â”€ Write comprehensive tests
```

### Phase 3: Scale & Optimize (Week 5-6)
```
â”œâ”€ Add auto-scaling for Spark workers
â”œâ”€ Implement model versioning (MLflow)
â”œâ”€ Optimize vector search (tune HNSW params)
â””â”€ Deploy to cloud (AWS/GCP)
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Anh Long Æ¡i, system Ä‘Ã£ sáºµn sÃ ng! ğŸ‰

Giá» anh cÃ³ thá»ƒ:
1. âœ… Start entire system vá»›i 1 command
2. âœ… Send events vÃ  see real-time recommendations
3. âœ… Monitor via multiple UIs
4. âœ… Scale components independently
5. âœ… Debug issues vá»›i detailed logs

HÃ£y test thá»­ vÃ  cho tÃ´i biáº¿t náº¿u anh cáº§n clarification hoáº·c thÃªm features nÃ o nhÃ©! ğŸš€