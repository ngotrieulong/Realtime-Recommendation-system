# üé¨ Real-Time Movie Recommendation System
## Production-Ready Lambda Architecture with Airflow 3.x + Spark 3.5 + Kafka


A complete, production-ready movie recommendation system implementing Lambda Architecture for both real-time and batch processing.

---

## üìã Table of Contents

- [Features](#-features)
- [Architecture](#-architecture)
- [Quick Start](#-quick-start)
- [Project Structure](#-project-structure)
- [Configuration](#-configuration)
- [Usage Examples](#-usage-examples)
- [Monitoring](#-monitoring)
- [Troubleshooting](#-troubleshooting)
- [Performance Tuning](#-performance-tuning)
- [Contributing](#-contributing)

---

## ‚ú® Features

### Real-Time Layer (Speed Layer)
- ‚ö° **Sub-second latency**: User interactions processed in < 500ms
- üéØ **Instant recommendations**: Updates recommendations within seconds of user action
- üìä **Event streaming**: Kafka-based event processing with exactly-once semantics
- üíæ **Multi-tier caching**: Redis (L1) ‚Üí Postgres (L2) ‚Üí Batch (L3)

### Batch Layer
- üîÑ **Daily model training**: Collaborative filtering with ALS (Alternating Least Squares)
- üìà **Historical analysis**: Process full user interaction history
- üéì **ML pipeline**: Complete MLOps workflow with model versioning
- üóÑÔ∏è **Data archival**: Automatic archival of old events to object storage

### Infrastructure
- üê≥ **Fully containerized**: Docker Compose orchestration
- üèóÔ∏è **Production-ready**: Multi-architecture support (ARM64 + AMD64)
- üìä **Monitoring-ready**: Health checks, metrics endpoints
- üîí **Security-hardened**: RBAC, secrets management, network isolation

---

## üèóÔ∏è Architecture

### Full System Diagram
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         USER'S BROWSER                          ‚îÇ
‚îÇ                      http://localhost:3000                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  React Application (Frontend)                                   ‚îÇ
‚îÇ  ‚îú‚îÄ Components: RecommendationPanel, MovieCard, Dashboard      ‚îÇ
‚îÇ  ‚îú‚îÄ State: userId, sessionId, recommendations[]                ‚îÇ
‚îÇ  ‚îî‚îÄ API Client: Fetch to http://localhost/api/*                ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚îÇ HTTP Requests
                     ‚îÇ (CORS: localhost:3000 allowed)
                     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    üåê NGINX API GATEWAY                         ‚îÇ
‚îÇ                      http://localhost/ (Port 80)                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ROUTING RULES:                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Pattern         Backend        Purpose                    ‚îÇ ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ
‚îÇ  ‚îÇ /api/*       ‚Üí  FastAPI:8000   Main API                  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ /admin/*     ‚Üí  Airflow:8080   Workflow UI               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ /storage/*   ‚Üí  MinIO:9001     File storage              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ /docs        ‚Üí  FastAPI:8000   API documentation         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ /health      ‚Üí  Gateway        Health check              ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  FEATURES:                                                      ‚îÇ
‚îÇ  ‚îú‚îÄ üõ°Ô∏è Rate Limiting:    100 req/min per IP                   ‚îÇ
‚îÇ  ‚îú‚îÄ üîí CORS Handling:    Centralized policy                   ‚îÇ
‚îÇ  ‚îú‚îÄ üìù Access Logging:   Detailed request logs                ‚îÇ
‚îÇ  ‚îú‚îÄ üîê Security Headers: X-Frame-Options, CSP, etc.           ‚îÇ
‚îÇ  ‚îú‚îÄ üì¶ Compression:      gzip (90% size reduction)            ‚îÇ
‚îÇ  ‚îú‚îÄ ‚ö° Connection Pool:  Keepalive to backends                ‚îÇ
‚îÇ  ‚îî‚îÄ üéØ Load Balancing:   (Future: Multiple FastAPI instances) ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ          ‚îÇ          ‚îÇ
   ‚îÇ          ‚îÇ          ‚îÇ Internal Network (Docker)
   ‚îÇ          ‚îÇ          ‚îÇ
   ‚Üì          ‚Üì          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        BACKEND SERVICES                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  FastAPI Application Server (Port 8000)                    ‚îÇ ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ
‚îÇ  ‚îÇ  Endpoints:                                                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ GET  /api/recommendations  (Hybrid L2+L3)              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ POST /api/events           (Kafka ‚Üí Spark)             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ GET  /api/movies            (Browse catalog)           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ GET  /api/metrics           (CTR, cache stats)         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ GET  /health                (Service status)           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  Logic:                                                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ L1 Cache Check (Redis)                                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ L2 Realtime Compute (pgvector)                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ L3 Batch Fallback (pre-computed)                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ Hybrid Blending (70% batch + 30% realtime)            ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                  ‚Üì                  ‚Üì                  ‚Üì         ‚îÇ
‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ               ‚Üì                  ‚Üì                  ‚Üì      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   Redis      ‚îÇ  ‚îÇ  Postgres    ‚îÇ  ‚îÇ    Kafka     ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Port 6379   ‚îÇ  ‚îÇ  Port 5432   ‚îÇ  ‚îÇ  Port 29092  ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ L1 Cache     ‚îÇ  ‚îÇ Tables:      ‚îÇ  ‚îÇ Topics:      ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ ‚îú‚îÄ recs:*    ‚îÇ  ‚îÇ ‚îú‚îÄ movies    ‚îÇ  ‚îÇ ‚îú‚îÄ movie-evts‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ ‚îî‚îÄ TTL: 1h   ‚îÇ  ‚îÇ ‚îú‚îÄ user_prof ‚îÇ  ‚îÇ ‚îî‚îÄ Consumers:‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ ‚îú‚îÄ batch_recs‚îÇ  ‚îÇ    Spark     ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Hit Rate:    ‚îÇ  ‚îÇ ‚îú‚îÄ rec_logs  ‚îÇ  ‚îÇ              ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ ~85%         ‚îÇ  ‚îÇ ‚îî‚îÄ rec_feed  ‚îÇ  ‚îÇ Retention:   ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ 7 days       ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                            ‚Üë                  ‚Üë           ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                ‚îÇ                  ‚îÇ             ‚îÇ
‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ              ‚îÇ                          ‚îÇ                       ‚îÇ
‚îÇ              ‚Üì                          ‚Üì                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ  Apache Spark          ‚îÇ  ‚îÇ  Apache Airflow        ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  (Master + Worker)     ‚îÇ  ‚îÇ  (Scheduler + Web)     ‚îÇ        ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§        ‚îÇ
‚îÇ  ‚îÇ                        ‚îÇ  ‚îÇ                        ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  Real-time Layer:      ‚îÇ  ‚îÇ  Batch Layer:          ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ Streaming Job      ‚îÇ  ‚îÇ  ‚îú‚îÄ DAG: batch_recs   ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  (Kafka consumer)   ‚îÇ  ‚îÇ  ‚îÇ  Schedule: 2 AM    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Interval: 5s       ‚îÇ  ‚îÇ  ‚îÇ                    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                     ‚îÇ  ‚îÇ  ‚îÇ  Tasks:            ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Updates:           ‚îÇ  ‚îÇ  ‚îÇ  1. Archive events ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  2. Train ALS model‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                     ‚îÇ  ‚îÇ  ‚îÇ  3. Generate recs  ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                     ‚îÇ  ‚îÇ  ‚îÇ  4. Atomic swap    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  Batch Layer:          ‚îÇ  ‚îÇ  ‚îÇ  5. Invalidate L1  ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ ALS Training       ‚îÇ  ‚îÇ  ‚îÇ                    ‚îÇ        ‚îÇ
‚îÇ     (nightly, triggered   ‚îÇ  ‚îÇ  ‚îî‚îÄ Port: 8080        ‚îÇ        ‚îÇ
‚îÇ      by Airflow)          ‚îÇ  ‚îÇ                        ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ                        ‚îÇ  ‚îÇ  Accessed via:         ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  Port: 7077 (master)   ‚îÇ  ‚îÇ  http://localhost/     ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  Port: 8081 (worker)   ‚îÇ  ‚îÇ         admin/         ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ              ‚Üì                                                  ‚îÇ
‚îÇ              ‚Üì                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ                    MinIO Object Storage                ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                   Port 9000 (API)                      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                   Port 9001 (Console)                  ‚îÇ    ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  Buckets:                                              ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ lakehouse/                                         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ models/                (Trained ALS models)    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ als_20250103_02am/                          ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ archived-events/        (Historical data)      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ 2025/01/03/events.parquet                   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ batch-recs-history/     (Daily snapshots)      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ checkpoints/            (Spark state)          ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                                                     ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  Accessed via:                                         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ Internal: s3a://lakehouse/                        ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ External: http://localhost/storage/               ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Request Flow with Gateway

**Example: Get Recommendations**

`TIMELINE: User requests personalized recommendations`

1.  **T=0ms | User's Browser**: `fetch('http://localhost/api/recommendations?user_id=user_123')`
2.  **T=5ms | Nginx Gateway (Port 80)**:
    *   CORS Check: Origin localhost:3000 ‚Üí ‚úÖ Allowed
    *   Rate Limit: IP 192.168.1.100 ‚Üí 45/100 requests ‚Üí ‚úÖ OK
    *   Route Match: `/api/*` ‚Üí FastAPI backend
    *   Proxy: `http://fastapi:8000/api/recommendations`
3.  **T=10ms | FastAPI (Port 8000)**:
    *   Check L1 Cache (Redis) ‚Üí MISS
    *   Get L2 Realtime Recs (pgvector)
    *   Get L3 Batch Recs (Postgres)
    *   Blend Hybrid (70% batch + 30% realtime)
    *   Cache Result in Redis
    *   Log to recommendation_logs
4.  **T=100ms | FastAPI Response**:
    *   Returns JSON with recommendations and metadata.
5.  **T=105ms | Nginx Gateway**:
    *   Adds Security Headers
    *   Compresses Response (gzip)
    *   Logs Request
6.  **T=110ms | User's Browser**:
    *   Response received and UI renders.


### Port Mapping with Gateway

| Port | Service | Accessible From | Purpose |
|------|---------|-----------------|---------|
| 80 | Nginx Gateway | External | **MAIN ENTRY POINT** |
| 3000 | React Frontend | External | User Interface |
| 8000 | FastAPI | Internal | API (via gateway) |
| 8080 | Airflow Web | Internal | Workflow UI (via gateway) |
| 9000 | MinIO API | Internal | Object storage (via gateway) |
| 9001 | MinIO Console | Internal | Storage UI (via gateway) |
| 5432 | Postgres | Internal | Database |
| 6379 | Redis | Internal | Cache |
| 29092| Kafka | Internal | Event stream |

### Security Layers

1.  **Layer 1: Network Isolation**: Frontend (Public) ‚Üí Gateway (Bridge) ‚Üí Backend (Private)
2.  **Layer 2: Gateway Policies**: Rate Limiting, CORS, Headers, Request Size
3.  **Layer 3: Application Security**: Input Validation, SQL Injection Protection
4.  **Layer 4: Data Security**: Password Auth, Access Keys

---

## üöÄ Quick Start

### Prerequisites

```bash
# Required
‚úÖ Docker Desktop (with 8GB RAM allocated)
‚úÖ Docker Compose V2+
‚úÖ 20GB+ free disk space
‚úÖ Mac M4 (ARM64) or Intel/AMD (AMD64)

# Verify installations
docker --version          # Should be 20.x+
docker compose version    # Should be 2.x+
```

### Installation (5 Minutes)

**Step 1: Clone Repository**
```bash
git clone <repository-url>
cd movie-recommendation-system
```

**Step 2: Configure Environment**
```bash
# Copy environment template
cp .env.example .env

# Edit .env file (optional, defaults work for local development)
vim .env
```

**Step 3: Start All Services**
```bash
# Start infrastructure
docker compose up -d

# Watch logs (optional)
docker compose logs -f
```

**Step 4: Wait for Health Checks** (2-3 minutes)
```bash
# Check service status
docker compose ps

# All services should show "healthy" status
```

**Step 5: Access UIs**

Open in browser:
```
üåê Frontend App:     http://localhost:3000
üåê API Gateway:      http://localhost/
   ‚îú‚îÄ Docs:          http://localhost/docs
   ‚îú‚îÄ Airflow:       http://localhost/admin
   ‚îî‚îÄ MinIO:         http://localhost/storage
```

### Verify Installation

```bash
# Test API Gateway health
curl http://localhost/health

# Expected response:
# Gateway OK

# Test recommendation endpoint via Gateway
curl "http://localhost/api/recommendations?user_id=test_user_1&limit=5"
```

---

## üìÅ Project Structure

```
movie-recommendation-system/
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yaml              # Main orchestration file
‚îú‚îÄ‚îÄ .env.example                     # Environment variables template
‚îú‚îÄ‚îÄ README.md                        # This file
‚îÇ
‚îú‚îÄ‚îÄ api-gateway/                     # NGINX API Gateway
‚îÇ   ‚îî‚îÄ‚îÄ nginx.conf                   # Routing and security config
‚îÇ
‚îú‚îÄ‚îÄ frontend/                        # React Application
‚îÇ   ‚îú‚îÄ‚îÄ src/                         # Source code
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile                   # Frontend container
‚îÇ
‚îú‚îÄ‚îÄ airflow/                         # Airflow 3.1.5 configuration
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                   # Custom Airflow image
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îÇ       ‚îî‚îÄ‚îÄ airflow.cfg              # Optional custom config
‚îÇ
‚îú‚îÄ‚îÄ dags/                            # Airflow DAGs
‚îÇ   ‚îú‚îÄ‚îÄ batch_recommendation_dag.py  # Daily batch processing
‚îÇ   ‚îî‚îÄ‚îÄ model_training_dag.py        # ML model training
‚îÇ
‚îú‚îÄ‚îÄ spark/                           # Spark 3.5.3 configuration
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile                   # Custom Spark image
‚îÇ
‚îú‚îÄ‚îÄ spark-jobs/                      # Spark applications
‚îÇ   ‚îú‚îÄ‚îÄ streaming_recommendations.py # Real-time processing
‚îÇ   ‚îî‚îÄ‚îÄ batch_model_training.py      # Batch ML training
‚îÇ
‚îú‚îÄ‚îÄ fastapi/                         # API application
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ app/
‚îÇ       ‚îú‚îÄ‚îÄ main.py                  # FastAPI application
‚îÇ       ‚îú‚îÄ‚îÄ config.py                # Configuration
‚îÇ       ‚îî‚îÄ‚îÄ models.py                # Pydantic models
‚îÇ
‚îú‚îÄ‚îÄ init-scripts/                    # Database initialization
‚îÇ   ‚îî‚îÄ‚îÄ init-pgvector.sql            # PostgreSQL schema
‚îÇ
‚îî‚îÄ‚îÄ docs/                            # Documentation
    ‚îú‚îÄ‚îÄ QUICK_START_GUIDE.md
    ‚îú‚îÄ‚îÄ AIRFLOW_3X_MIGRATION_GUIDE.md
    ‚îî‚îÄ‚îÄ DOCKERFILE_FIXES_CHANGELOG.md
```

---

## ‚öôÔ∏è Configuration

### Resource Allocation (8GB Docker Memory)

Default allocation optimized for Mac M4 16GB (8GB Docker limit):

| Service          | Memory | CPUs | Purpose                    |
|------------------|--------|------|----------------------------|
| Spark Worker     | 1.5GB  | 2.0  | Data processing            |
| Kafka            | 768MB  | 1.0  | Message broker             |
| Postgres         | 512MB  | 0.5  | Database                   |
| MinIO            | 512MB  | 0.5  | Object storage             |
| Airflow Web      | 512MB  | 0.5  | UI                         |
| Airflow Scheduler| 512MB  | 0.5  | Orchestration              |
| Redis            | 256MB  | 0.25 | Cache                      |
| FastAPI          | 256MB  | 0.5  | API                        |
| Spark Master     | 256MB  | 0.5  | Coordinator                |
| Zookeeper        | 256MB  | 0.25 | Kafka coordination         |
| Nginx Gateway    | 128MB  | 0.25 | API Gateway                |
| Frontend         | 128MB  | 0.25 | UI                         |

**Total: ~5.6GB** (2.4GB buffer for system)

### Environment Variables

Key variables in `.env`:

```bash
# Performance tuning
AIRFLOW__CORE__PARALLELISM=32              # Concurrent tasks
SPARK_WORKER_MEMORY=1536m                  # Spark worker RAM
POSTGRES_MAX_CONNECTIONS=150               # DB connections

# Security (CHANGE IN PRODUCTION!)
AIRFLOW__CORE__FERNET_KEY=<generate-new>
POSTGRES_PASSWORD=<strong-password>
MINIO_ROOT_PASSWORD=<strong-password>

# Application settings
RECOMMENDATION_CACHE_TTL=3600              # Cache TTL (seconds)
SPARK_STREAMING_BATCH_INTERVAL=5           # Micro-batch interval
```

See `.env.example` for full list of options.

---

## üì° API Reference

### Endpoints

#### `GET /api/recommendations`
Get personalized movie recommendations for a user (Hybrid: Batch + Real-time).

**Request Parameters:**
- `user_id` (str): Unique user identifier
- `limit` (int): Number of recommendations (default: 10)

**Response:**
```json
{
  "user_id": "user_123",
  "recommendations": [
    {
      "movie_id": "m_inception",
      "title": "Inception",
      "score": 0.98,
      "poster_url": "https://upload.wikimedia..."
    }
  ],
  "source": "hybrid",
  "latency_ms": 45
}
```

#### `POST /api/events`
Track user interaction events (clicks, ratings, watches) for processing.

**Request Body:**
```json
{
  "user_id": "user_123",
  "movie_id": "m_inception",
  "event_type": "rate",
  "value": 5
}
```

**Response:**
```json
{
  "status": "accepted",
  "message": "Event queued for processing"
}
```

#### `GET /api/movies`
Browse the movie catalog with genre filtering.

**Request Parameters:**
- `limit` (int): Items per page
- `offset` (int): Pagination offset
- `genre` (str): Filter by genre (optional)

**Response:**
```json
{
  "movies": [...],
  "count": 50,
  "limit": 50
}
```

#### `GET /health`
Basic health check for load balancers.

**Response:** `{"status": "healthy"}`

---

## üîß Feature Engineering

### Feature Categories
The system generates features across two distinct timelines (Batch & Real-time):

| Category | Window | Features | Description |
|----------|--------|----------|-------------|
| **Movie Stats** | Batch (Daily) | `avg_rating`, `total_ratings`, `genre_dist` | Long-term popularity metrics |
| **User Profile** | Batch (Daily) | `fav_genres`, `view_count`, `avg_given_rating` | User's historical preferences |
| **Real-time Context** | Stream (5s) | `current_session_clicks`, `recent_genre_affinity` | Immediate user intent signals |
| **Content Embeddings** | Static | `bert_embedding` (768d) | Semantic vector from overview |

### Feature Generation
Features are computed/stored in three places:

1.  **Postgres (`movies` table)**: Static metadata and batch statistics.
2.  **Redis (Cache)**: Real-time session context and recency signals.
3.  **pgvector**: Vector embeddings for semantic similarity search.

```python
# Example: Hybrid Feature Combination
combined_score = (
    (batch_cf_score * 0.7) +       # Long-term preference (ALS)
    (realtime_content_score * 0.3) # Short-term intent (Vector Sim)
)
```

---

## üéì Model Training

### Training Pipeline
The ML pipeline (`dags/model_training_dag.py`) executes nightly:

1.  **Data Extraction**: Spark reads raw events from `archived-events/`.
2.  **Preprocessing**: Filters outliers and normalizes ratings.
3.  **Model Training**: Trains an **ALS (Alternating Least Squares)** matrix factorization model.
    *   *Implicit Feedback*: Uses views/clicks as confidence.
    *   *Explicit Feedback*: Uses ratings as targets.
4.  **Evaluation**: Calculates RMSE and Precision@K on a holdout set.
5.  **Model Register**: Saves user/item factors to Postgres for serving.

### Model Selection
We primarily use **Matrix Factorization** for the Batch Layer due to its scalability:

```python
# Spark ALS Configuration
als = ALS(
    maxIter=10,
    regParam=0.1,
    userCol="user_id_int",
    itemCol="movie_id_int",
    ratingCol="rating",
    coldStartStrategy="drop"
)
```

### Evaluation Metrics

| Metric | Definition | Target |
|--------|------------|--------|
| **RMSE** | Root Mean Square Error of rating prediction | < 0.8 |
| **Precision@K** | % of relevant items in top-K recs | > 0.15 |
| **Coverage** | % of total catalog recommended to at least 1 user | > 80% |

---

## üìä Monitoring

### Health Checks

```bash
# All services health
./scripts/health_check.sh

# Individual service health
curl http://localhost/health          # Gateway
curl http://localhost/api/health      # FastAPI (via Gateway)
curl http://localhost/admin/health    # Airflow (via Gateway)
```

### Metrics

```bash
# FastAPI metrics
curl http://localhost/api/metrics

# Example response:
# {
#   "total_requests": 15234,
#   "cache_hit_rate": 0.87,
#   "avg_response_time_ms": 12.3
# }
```

### Logs

```bash
# View all logs
docker compose logs -f

# Service-specific logs
docker compose logs -f fastapi
docker compose logs -f airflow-scheduler
docker compose logs -f spark-worker
docker compose logs -f nginx
docker compose logs -f frontend

# Airflow task logs
docker exec airflow-webserver \
  airflow tasks logs batch_recommendation_processing <task_id> <execution_date>
```

---

## üîß Troubleshooting

### Services Won't Start

```bash
# Check Docker resources
docker system df
docker stats

# Clean up
docker system prune -f
docker volume prune -f

# Restart services
docker compose down
docker compose up -d
```

### Health Checks Failing

**Problem**: Container marked as "unhealthy"

```bash
# Check specific service logs
docker logs kafka

# Common issues:
# 1. Kafka: Wait 30+ seconds for full startup
# 2. Postgres: Database still initializing
# 3. Airflow: DB migration in progress

# Solution: Wait and check again
docker compose ps
```

### Out of Memory Errors

**Problem**: `OOMKilled` or `java.lang.OutOfMemoryError`

```bash
# Check Docker memory limit
docker info | grep Memory

# Solution 1: Increase Docker memory (Docker Desktop ‚Üí Settings)
# Solution 2: Reduce memory allocation in docker-compose.yaml
```

### Spark Job Failures

**Problem**: Spark jobs fail with connection errors

```bash
# Verify Spark cluster health
curl http://localhost:8088

# Check if worker is registered
# UI should show 1 worker with 2 cores, 1.5GB memory

# Common issues:
# 1. JAVA_HOME not set ‚Üí Check Spark Dockerfile
# 2. JAR conflicts ‚Üí Verify hadoop-aws versions match
# 3. Memory exceeded ‚Üí Reduce executor memory

# Test Spark submit
docker exec spark-master \
  /opt/spark/bin/spark-submit \
  --version
```

### Database Connection Issues

```bash
# Test Postgres connection
docker exec -it postgres \
  psql -U airflow -d moviedb -c "SELECT COUNT(*) FROM movies;"

# Test from FastAPI container
docker exec -it fastapi \
  python -c "import asyncpg; import asyncio; asyncio.run(asyncpg.connect('postgresql://airflow:airflow@postgres:5432/moviedb'))"
```

---

## üéØ Performance Tuning

### For Higher Throughput

```yaml
# In .env or docker-compose.yaml
environment:
  # Increase parallelism
  - AIRFLOW__CORE__PARALLELISM=64
  - AIRFLOW__SCHEDULER__MAX_TIS_PER_QUERY=512
  
  # More Spark resources
  - SPARK_WORKER_MEMORY=4g
  - SPARK_WORKER_CORES=4
  
  # More database connections
  - POSTGRES_MAX_CONNECTIONS=300
  - AIRFLOW__DATABASE__SQL_ALCHEMY_POOL_SIZE=20
```

### For Lower Latency

```yaml
# Reduce batch intervals
environment:
  - SPARK_STREAMING_BATCH_INTERVAL=2  # From 5s to 2s
  
# More aggressive caching
  - RECOMMENDATION_CACHE_TTL=7200  # 2 hours
  
# Increase Redis memory
  - REDIS_MAX_MEMORY=512mb
```

### For Better Accuracy

```yaml
# Longer model training
environment:
  - ALS_MAX_ITER=20        # From 10 to 20
  - ALS_RANK=20            # More latent factors
  - RECOMMENDATION_TOP_N=100  # Generate more candidates
```

---

## üìù Development

### Running Tests

```bash
# Unit tests
docker exec fastapi pytest tests/

# Integration tests
docker exec airflow-webserver \
  airflow dags test batch_recommendation_processing 2025-01-01
```

### Hot Reload (Development Mode)

FastAPI and Airflow DAGs support hot reload:

```bash
# Edit files locally
vim fastapi/app/main.py
vim dags/batch_recommendation_dag.py

# Changes apply immediately (mounted volumes)
# No need to rebuild containers
```

### Rebuilding After Code Changes

```bash
# Rebuild specific service
docker compose build airflow-webserver
docker compose up -d airflow-webserver

# Rebuild all
docker compose build
docker compose up -d
```

---

## ü§ù Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## üìÑ License

MIT License - see [LICENSE](LICENSE) file for details

---

## üôè Acknowledgments

- Apache Airflow team for the excellent 3.x release
- Apache Spark community
- pgvector maintainers
- FastAPI creator Sebasti√°n Ram√≠rez

---

## üìö Additional Documentation

- [Airflow 3.x Migration Guide](docs/AIRFLOW_3X_MIGRATION_GUIDE.md)
- [Dockerfile Fixes Changelog](docs/DOCKERFILE_FIXES_CHANGELOG.md)
- [Quick Start Guide](docs/QUICK_START_GUIDE.md)

---

**Built with ‚ù§Ô∏è for production ML systems**